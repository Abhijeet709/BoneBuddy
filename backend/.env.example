# Copy to env.local and adjust as needed (do not commit env.local)
# Report generation uses Ollama (free, local Llama) by default. No key required.
# Optional: override to use OpenAI or another API
# LLM_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=llama3.2
# OPENAI_API_KEY=your_key_if_using_openai

# Docker: MURA dataset path for training (used by docker-compose --profile train)
# Use forward slashes on Windows, e.g. C:/Users/abhij/Downloads/mura_dataset/MURA-v1.1
# MURA_DATA_DIR=C:/Users/abhij/Downloads/mura_dataset/MURA-v1.1
